{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59c7577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85749ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(u'i may want to visit tokyo in the next May, and see  the famous tokyo tower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79aa2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No named entities found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff01e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo - GPE - Countries, cities, states\n",
      "the next May - DATE - Absolute or relative dates or periods\n",
      "  - NORP - Nationalities or religious or political groups\n",
      "tokyo - GPE - Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b78090a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington, DC - GPE - Countries, cities, states\n",
      "next May - DATE - Absolute or relative dates or periods\n",
      "the Washington Monument - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'May I go to Washington, DC next May to see the Washington Monument?')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1d1c067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 - MONEY - Monetary values, including unit\n",
      "Paytm - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(u\"Tesla have bought $500 worth shares of Paytm company\")\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a03b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "ORG=doc.vocab.strings[u'ORG']\n",
    "new_ent=Span(doc,8,9,label=ORG)\n",
    "doc.ents=list(doc.ents)+[new_ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb68af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 - MONEY - Monetary values, including unit\n",
      "Paytm - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d585616",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2=nlp(u'readme-10 is a cheapest and high end smartphone. '\n",
    "         u'readme 10 is also most sold smartphone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6927ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readme-10 - PERSON - People, including fictional\n",
      "10 - CARDINAL - Numerals that do not fall under another type\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2fea679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher=PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f6f59ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4452177204818730156, 0, 1), (4452177204818730156, 9, 11)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_list=['readme-10','readme 10']\n",
    "pattern_list=[nlp(pattern) for pattern in phrase_list]\n",
    "matcher.add('newProduct',None,*pattern_list)\n",
    "matches=matcher(doc2)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95ae468f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4452177204818730156, 0, 1), (4452177204818730156, 9, 11)]\n",
      "readme-10 - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "readme 10 - PRODUCT - Objects, vehicles, foods, etc. (not services)\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "PROD = doc2.vocab.strings[u'PRODUCT']\n",
    "print(matches)\n",
    "new_ents=[Span(doc2,match[1],match[2],label=PROD) for match in matches]\n",
    "doc2.ents=list(doc2.ents)+new_ents\n",
    "show_ents(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78f2bd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    readme-10\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " is a cheapest and high end smartphone. \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    readme 10\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " is also most sold smartphone</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "colors = {'PRODUCT': 'linear-gradient(90deg, #aa9cfc, #fc9ce7)', 'ORG': 'radial-gradient(yellow, green)'}\n",
    "options = {'ents': ['ORG', 'PRODUCT'], 'colors':colors}\n",
    "displacy.render(doc2,style='ent',jupyter=True,options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e00205",
   "metadata": {},
   "source": [
    "## adding segmentation rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "754e5a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right; leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "# SPACY'S DEFAULT BEHAVIOR\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "doc3 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "\n",
    "for sent in doc3.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "318d224e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'set_custom_boundary', 'parser', 'ner']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## setting custom boundary  and adding to the existing boundary rule\n",
    "def set_custom_boundary(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text==';':\n",
    "            doc[token.i+1].is_sent_start=True\n",
    "    return doc\n",
    "nlp.add_pipe(set_custom_boundary, before='parser')\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6437120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right;\n",
      "leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "\n",
    "for sent in doc3.sents:\n",
    "    print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bae5ccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sentence', '.']\n",
      "['This', 'is', 'another', '.', '\\n\\n']\n",
      "['This', 'is', 'a', '\\n', 'third', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')  # reset to the original\n",
    "\n",
    "mystring = u\"This is a sentence. This is another.\\n\\nThis is a \\nthird sentence.\"\n",
    "\n",
    "# SPACY DEFAULT BEHAVIOR:\n",
    "doc = nlp(mystring)\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print([token.text for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f356057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGING THE RULES\n",
    "from spacy.pipeline import SentenceSegmenter\n",
    "\n",
    "def split_on_newlines(doc):\n",
    "    start = 0\n",
    "    seen_newline = False\n",
    "    for word in doc:\n",
    "        if seen_newline:\n",
    "            yield doc[start:word.i]\n",
    "            start = word.i\n",
    "            seen_newline = False\n",
    "        elif word.text.startswith('\\n'): # handles multiple occurrences\n",
    "            seen_newline = True\n",
    "    yield doc[start:]      # handles the last group of tokens\n",
    "\n",
    "\n",
    "sbd = SentenceSegmenter(nlp.vocab, strategy=split_on_newlines)\n",
    "nlp.add_pipe(sbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e1e8071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sentence', '.', 'This', 'is', 'another', '.', '\\n\\n']\n",
      "['This', 'is', 'a', '\\n']\n",
      "['third', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(mystring)\n",
    "for sent in doc.sents:\n",
    "    print([token.text for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232c0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
